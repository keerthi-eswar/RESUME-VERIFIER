# AI-Based Smart Resume Screening System

## ğŸ“‹ Project Overview

An intelligent, cloud-ready resume screening system that ranks resumes based on semantic similarity with job descriptions using Machine Learning embeddings. Unlike traditional keyword-based ATS systems, this system understands contextual meaning and captures semantic relationships between job requirements and candidate qualifications.

### Key Features
- ğŸ¤– **Semantic Understanding**: Uses embeddings to understand meaning beyond keywords
- ğŸ“Š **Smart Ranking**: Ranks resumes by relevance using cosine similarity
- âš¡ **Fast Processing**: Batch processing of multiple resumes
- ğŸ¯ **Scalable**: Cloud-ready REST API architecture
- ğŸ“± **User-Friendly**: Web interface for recruiters
- ğŸ“¥ **Multiple Formats**: Supports PDF and DOCX resumes

---

## ğŸ—ï¸ Project Structure

```
resume-screening-system/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ config.py               # Configuration management
â”‚   â”œâ”€â”€ document_processor.py    # PDF/DOCX text extraction
â”‚   â”œâ”€â”€ embedding_generator.py   # Semantic embeddings
â”‚   â”œâ”€â”€ similarity_calculator.py # Cosine similarity calculation
â”‚   â””â”€â”€ models.py               # Pydantic data models
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                  # Streamlit web interface
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_handler.py         # File utilities
â”‚   â””â”€â”€ logger.py               # Logging configuration
â”œâ”€â”€ sample_data/
â”‚   â”œâ”€â”€ sample_job_description.txt
â”‚   â””â”€â”€ sample_resume.txt
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example                # Environment variables template
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ SETUP_GUIDE.md              # Detailed setup instructions
â””â”€â”€ DEPLOYMENT.md               # Deployment guide
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- pip package manager
- Optional: Azure account (for production deployment)

### Installation

1. **Clone/Download the project**
```bash
cd resume-screening-system
```

2. **Create virtual environment**
```bash
python -m venv venv

# On Windows
venv\Scripts\activate

# On macOS/Linux
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment**
```bash
# Copy .env.example to .env
cp .env.example .env

# Edit .env with your settings (optional for basic usage)
```

5. **Run the backend API**
```bash
python -m backend.main
```
The API will start at `http://localhost:8000`

6. **In a new terminal, run the frontend**
```bash
streamlit run frontend/app.py
```
The interface will open at `http://localhost:8501`

---

## ğŸ“– How to Use

### Step 1: Prepare Job Description
- Copy your job description text
- Paste it in the "Job Description" field in the web interface

### Step 2: Upload Resumes
- Click "Upload Resumes" button
- Select one or multiple PDF or DOCX files
- Supported formats: `.pdf`, `.docx`

### Step 3: Run Analysis
- Click "ğŸ” Screen Resumes" button
- Wait for processing to complete

### Step 4: View Results
- See ranked candidates with similarity scores
- Download results as CSV
- View detailed analysis metrics

---

## ğŸ”§ Technology Stack

### Backend
- **FastAPI**: Modern, fast web framework
- **Python**: Core language
- **Sentence Transformers**: Pre-trained embedding models
- **Scikit-learn**: Machine learning utilities
- **PyPDF2**: PDF parsing
- **python-docx**: DOCX parsing

### Frontend
- **Streamlit**: Web application framework
- **Pandas**: Data manipulation
- **Requests**: HTTP client

### ML/NLP
- **Transformers (BERT)**: Pre-trained language models
- **NumPy**: Numerical computing
- **Cosine Similarity**: Ranking algorithm

---

## ğŸ“Š Algorithm Explanation

### Cosine Similarity Formula
```
Similarity = (A Â· B) / (||A|| Ã— ||B||)

Where:
- A = Job description embedding vector
- B = Resume embedding vector
- Â· = Dot product
- ||X|| = Vector norm (magnitude)
```

### Process Flow
1. **Text Extraction**: Convert PDF/DOCX â†’ Plain text
2. **Preprocessing**: Remove special characters, normalize text
3. **Embedding Generation**: Convert text â†’ semantic vectors (1536 dimensions)
4. **Similarity Calculation**: Compute cosine similarity between JD and resumes
5. **Ranking**: Sort resumes by scores (descending)
6. **Display**: Show ranked results with metrics

---

## ğŸ“ Sample Usage

### Input Example
**Job Description:**
```
We're looking for a Python Developer with 3+ years experience.
Must have knowledge of FastAPI, PostgreSQL, and AWS.
Experience with Docker and Kubernetes is preferred.
```

**Resume:**
```
John Doe - Senior Python Developer
- 5 years of Python development experience
- Expertise in FastAPI and Django
- PostgreSQL and MySQL database management
- AWS and Docker containerization
- Kubernetes orchestration
```

### Output Example
```
Rank  Candidate Name     Similarity Score  Match %  Relevance
1     John Doe          0.8934            89.34%   ğŸŸ¢ Highly Relevant
2     Jane Smith        0.7654            76.54%   ğŸŸ¡ Relevant
3     Bob Johnson       0.6234            62.34%   ğŸŸ¡ Relevant
```

---

## ğŸ” Security Considerations

- File uploads are processed in-memory (not stored permanently)
- Use HTTPS in production
- Implement authentication for API endpoints
- Validate file types and sizes
- Store credentials in environment variables

---

## ğŸš¢ Deployment

### Local Development
See `SETUP_GUIDE.md` for detailed local setup

### Azure Deployment
See `DEPLOYMENT.md` for cloud deployment instructions

### Docker Deployment
```bash
# Build Docker image
docker build -t resume-screening .

# Run container
docker run -p 8000:8000 -p 8501:8501 resume-screening
```

---

## ğŸ“ˆ Performance Metrics

### Typical Performance
- **Text Extraction**: ~100ms per document
- **Embedding Generation**: ~200ms per document
- **Similarity Calculation**: ~1ms per comparison
- **Total Time for 10 Resumes**: ~3-5 seconds

### Comparison Metrics
| Metric | Traditional ATS | This System |
|--------|-----------------|-------------|
| Keyword Dependency | High | Low |
| Semantic Understanding | No | Yes |
| Processing Speed | Fast | Very Fast |
| Bias Detection | Limited | Potential |
| Scalability | Moderate | High |

---

## ğŸ”„ Future Enhancements

- [ ] Bias detection and mitigation
- [ ] Skill gap analysis
- [ ] Interview question generation
- [ ] Multi-language resume support
- [ ] LinkedIn integration
- [ ] Explainable AI (XAI) layer
- [ ] Database integration for resume history
- [ ] Machine learning model training with labeled data

---

## ğŸ› Troubleshooting

### API won't start
```bash
# Check if port 8000 is available
netstat -ano | findstr :8000  # Windows
lsof -i :8000                # macOS/Linux

# Try different port
PORT=8001 python -m backend.main
```

### Streamlit connection error
```bash
# Edit frontend/app.py and change API URL:
api_url = "http://localhost:8000"  # Correct the URL
```

### Out of memory error
- Reduce number of resumes processed at once
- Use a lighter embedding model
- Increase available RAM

---

## ğŸ“š References

- [Sentence Transformers Documentation](https://www.sbert.net/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [BERT Paper](https://arxiv.org/abs/1810.04805)
- [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)

---

## ğŸ“„ License

This project is provided for educational purposes.

---

## ğŸ‘¥ Contributing

Contributions are welcome! Please feel free to submit pull requests or open issues.

---

## â“ FAQ

**Q: Can I use this for production recruitment?**
A: Yes, but add authentication, audit logging, and bias detection features.

**Q: How do I improve accuracy?**
A: Use better embedding models (all-mpnet-base-v2) or fine-tune with your data.

**Q: Can I integrate with my HR system?**
A: Yes, the REST API can be integrated with any system via HTTP requests.

**Q: How many resumes can it process?**
A: Limited by available RAM. Typically 100-1000 resumes per batch.

---

## ğŸ“ Support

For questions or issues, please refer to the documentation files or open an issue on the project repository.

**Project Created For:** BTech/BCA Mini Project (2-3 Year Students)
**Last Updated:** February 2024
